# -*- coding: utf-8 -*-
"""Project_6_Classifier_Visualizations.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E-yavpjWjyOHAVs2sp9f3tUuG1J6--YE
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import seaborn as sns

# importing libraries for NLP

import spacy
from spacy.lang.en.stop_words import STOP_WORDS as stopwords
import re

from google.colab import drive
drive.mount('/content/drive')

"""# Loading Data"""

data = pd.read_csv('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Datasets/train_val_df.csv',index_col=0)

"""### Making a Copy of the Data"""

data2= data.copy()

data2.head(2)

data2.columns

data2.drop(['complete', 'comp_stem', 'comp_lem', 'summary', 'sum_stem','sum_lem'],axis=1, inplace=True)

data2.head()



"""### Counting the data"""

data2.value_counts().sum()

"""### Checking the information of the data"""

data2.info()

data2.describe()

"""### Checking for missing data"""

data2.isnull().sum()

sns.heatmap(data2.isnull(),cmap='viridis',yticklabels=False,cbar=False);

"""### Dropping missing values"""

data2.dropna(inplace=True)

data2.isnull().sum()

data2.head(3)

"""### Checking the column"""

data2.columns

"""### Checking for blank spaces in `clean`"""

blankspace = []


for index, clean, labels in data2.itertuples():
    if clean.isspace():
        blankspace.append(index)
    else:
        False

print(f""" 
Length of blank spaces : {len(blankspace)}""")

"""### Checking the `Labels`"""

data2['labels'].value_counts()

sns.set_theme(style="whitegrid")
plt.figure(dpi = 111)
sns.countplot(x='labels', data= data2)
plt.xticks(rotation=70)
plt.title("Class Labels")
plt.savefig("class_labels.png")

data2['labels'].value_counts().plot.pie(autopct='%1.2f%%',figsize=(16,10))
plt.savefig("Pie_chat.png")

"""# Exploring the `clean` column"""

data2.head(3)

"""## Creating a new dataframe for  clean"""

data3 = data2.copy()

data3.sample(5)

"""### Getting word count """

data2['word_counts'] = data2['clean'].apply(lambda x: len(str(x).split()))

data2.head()

"""### Characters Count"""

def char_counts(x):
    s = x.split()
    x = ''.join(s)
    return len(x)

data2['char_counts'] = data2['clean'].apply(lambda x: char_counts(str(x)))

data2.head()

"""### Average word length"""

data2['avg_word_len'] = data2['char_counts']/data2['word_counts']

data2.head()

"""### Stop Words Count"""

#stopwords  --> imported from spacy

data2['stop_words_len'] = data2['clean'].apply(lambda x: len([t for t in x.split() if t in stopwords]))

data2.head()

"""### UPPER case words count"""

data2['upper_case_counts'] = data2['clean'].apply(lambda x: len([t for t in x.split() if t.isupper()]))

data2.head(5)

"""### Checking for URLs"""

data2['url_flags'] = data['clean'].apply(lambda x: len(re.findall(r'(http|https|ftp|ssh)://([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:/~+#-]*[\w@?^=%&/~+#-])?', x)))

data2[data2['url_flags']>0]

# Checking how many rows has urls

len(data2[data2['url_flags']>0])

"""### Checking for emails"""

data2['emails'] = data2['clean'].apply(lambda x: re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\.[a-z0-9+_-]+\b)', x))

data2.head()

data2['emails_count'] = data2['emails'].apply(lambda x: len(x))

data2[data2['emails_count']>0]

# Number of rows with emails

len(data2[data2['emails_count']>0])

"""# Visual Analysis of Features"""

data2.columns

# # Let us write a function that will help us create boxplot and histogram for any input numerical
# # variable.
# # This function takes the numerical column as the input and returns the boxplots
# # and histograms for the variable.
# # Let us see if this help us write faster and cleaner code.
# def histogram_boxplot(feature, figsize=(15, 10), bins=None):
#     """Boxplot and histogram combined
#     feature: 1-d feature array
#     figsize: size of fig (default (9,8))
#     bins: number of bins (default None / auto)
#     """
#     f2, (ax_box2, ax_hist2) = plt.subplots(
#         nrows=2,  # Number of rows of the subplot grid= 2
#         sharex=True,  # x-axis will be shared among all subplots
#         gridspec_kw={"height_ratios": (0.25, 0.75)},
#         figsize=figsize,
#     )  # creating the 2 subplots
#     sns.boxplot(
#         feature, ax=ax_box2, showmeans=True, color="violet"
#     )  # boxplot will be created and a star will indicate the mean value of the column
#     sns.distplot(
#         feature, kde=F, ax=ax_hist2, bins=40, palette="winter"
#     ) if bins else sns.distplot(
#         feature, kde=False, ax=ax_hist2
#     )  # For histogram
#     ax_hist2.axvline(
#         np.mean(feature), color="green", linestyle="--"
#     )  # Add mean to the histogram
#     ax_hist2.axvline(
#         np.median(feature), color="black", linestyle="-"
#     )  # Add median to the histogram

# Observations on Customer_age
# histogram_boxplot(data2["word_counts"])

# Observations on Customer_age
# histogram_boxplot(data2["avg_word_len"]);

plt.figure(figsize=(20,20))

sns.barplot(x='labels',y='word_counts',data=data2)
plt.title('Word Counts by Label', fontsize=48)
plt.xticks(fontsize=28, rotation=15)
plt.xlabel('Labels', fontsize=36)
plt.yticks(fontsize=28)
plt.ylim(bottom=600, top=1600)
plt.ylabel('Word Counts', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/Label_WordCounts', transparent=True)
plt.show()

plt.figure(figsize=(20,20))
sns.barplot(x='labels',y='avg_word_len',data=data2)
plt.title('Average Word Length by Label', fontsize=48)
plt.xticks(fontsize=28, rotation=15)
plt.xlabel('Labels', fontsize=36)
plt.ylim(bottom=4.7 , top=5)
plt.yticks(ticks=[4.7, 4.8, 4.9, 5.0, 5.1], fontsize=28)
plt.ylabel('Avg Word Length', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/Label_Avg_Wrd_Len', transparent=True)
plt.show()

# #plot data
# fig, ax = plt.subplots(figsize=(15,7))
# data2.groupby(['word_counts']).count()['labels'].plot(ax=ax)

samp1 = data2[data2['labels'] == 'Sports']
max_1 = samp1['word_counts'].max()
samp2 = data2[data2['labels'] == 'Entertainment']
max_2 = samp2['word_counts'].max()

plt.figure(figsize=(20,20))
plt.title('Sports and Entertainment', fontsize=48)
sns.kdeplot(data2[data2['labels']=='Sports']['word_counts'], shade=True, color='green',label='Sports')
sns.kdeplot(data2[data2['labels']=='Entertainment']['word_counts'], shade=True, color='red', label='Entertainment')
plt.legend(fontsize='xx-large')
plt.xticks(ticks=range(0,10000,2000), fontsize=28)
plt.xlabel('Word Counts', fontsize=36)
plt.xlim(left=0, right=10000)
plt.axvline(x=max_1, ymax=.25, color='green', linewidth=3)
plt.axvline(x=max_2, ymax=.25, color='red', linewidth=3)
plt.yticks(fontsize=28)
plt.ylabel('Density', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/Sports_v_Entertainment_Word_Counts', transparent=True)
plt.show()

samp1 = data2[data2['labels'] == 'Economy']
max_1 = samp1['word_counts'].max()
samp2 = data2[data2['labels'] == 'Education']
max_2 = samp2['word_counts'].max()

plt.figure(figsize=(20,20))
plt.title('Economy and Education', fontsize=48)

sns.kdeplot(data2[data2['labels']=='Economy']['word_counts'], shade=True, color='red', label ='Economy')
sns.kdeplot(data2[data2['labels']=='Education']['word_counts'], shade=True, color='green', label='Education')
plt.legend(fontsize='xx-large')
plt.xticks(ticks=range(0,8000,2000), fontsize=28)
plt.xlabel('Word Counts', fontsize=36)
plt.xlim(left=0, right=6000)
plt.axvline(x=max_1, ymax=.25, color='red', linewidth=3 )
plt.axvline(x=max_2, ymax=.25, color='green', linewidth=3)
plt.yticks(fontsize=28)
plt.ylabel('Density', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/Economy_v_Education_Word_Counts', transparent=True)
plt.show()

# plt.figure(figsize=(12,9))
# plt.title('Entertainment and Education', fontsize=25)

# sns.kdeplot(data2[data2['labels']=='Entertainment']['word_counts'], shade=True, color='magenta', label='Entertainment')
# sns.kdeplot(data2[data2['labels']=='Education']['word_counts'], shade=True, color='blue', label='Education')
# plt.legend()
# plt.savefig('word_counts_class_labels.png')

# plt.figure(figsize=(12,9))
# plt.title('Economy and Entertainment', fontsize=25)

# sns.kdeplot(data2[data2['labels']=='Economy']['word_counts'], shade=True, color='red', label='Economy')
# sns.kdeplot(data2[data2['labels']=='Entertainment']['word_counts'], shade=True, color='magenta', label='Entertainment')
# plt.legend()
# plt.savefig('word_counts_class_labels.png')

samp1 = data2[data2['labels'] == 'Economy']
max_1 = samp1['word_counts'].max()
samp2 = data2[data2['labels'] == 'Entertainment']
max_2 = samp2['word_counts'].max()
samp3 = data2[data2['labels'] == 'Education']
max_3 = samp3['word_counts'].max()
samp4 = data2[data2['labels'] == 'Environment']
max_4 = samp4['word_counts'].max()
samp5 = data2[data2['labels'] == 'Sports']
max_5 = samp5['word_counts'].max()
samp6 = data2[data2['labels'] == 'Technology']
max_6 = samp6['word_counts'].max()
samp7 = data2[data2['labels'] == 'Health']
max_7 = samp7['word_counts'].max()


plt.figure(figsize=(20,20))

plt.title('Word Counts of all Labels', fontsize=48)
sns.kdeplot(data2[data2['labels']=='Economy']['word_counts'], shade=True, color='red', label='Economy')
sns.kdeplot(data2[data2['labels']=='Entertainment']['word_counts'], shade=True, color='magenta', label='Entertainment')
sns.kdeplot(data2[data2['labels']=='Education']['word_counts'], shade=True, color='blue', label='Education')
sns.kdeplot(data2[data2['labels']=='Environment']['word_counts'], shade=True, color='yellow', label ='Environment')
sns.kdeplot(data2[data2['labels']=='Sports']['word_counts'], shade=True, color='green', label='Sports')
sns.kdeplot(data2[data2['labels']=='Technology']['word_counts'], shade=True, color='purple',label='Technology')
sns.kdeplot(data2[data2['labels']=='Health']['word_counts'], shade=True, color='skyblue', label='Health')
plt.legend(fontsize='xx-large')
plt.xticks(ticks=range(0,10000,2000), fontsize=28)
plt.xlabel('Word Counts', fontsize=36)
plt.xlim(left=0, right=8000)
plt.axvline(x=max_1, ymax=.25, color='red', linewidth=3)
plt.axvline(x=max_2, ymax=.25, color='magenta', linewidth=3)
plt.axvline(x=max_3, ymax=.25, color='blue', linewidth=3)
plt.axvline(x=max_4, ymax=.25, color='yellow', linewidth=3)
plt.axvline(x=max_5, ymax=.25, color='green', linewidth=3)
plt.axvline(x=max_6, ymax=.25, color='purple', linewidth=3)
plt.axvline(x=max_7, ymax=.25, color='skyblue', linewidth=3)
plt.yticks(fontsize=28)
plt.ylabel('Density', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/All_Label_Word_Counts', transparent=True)
plt.show()

samp1 = data2[data2['labels'] == 'Economy']
max_1 = samp1['avg_word_len'].mean()
samp2 = data2[data2['labels'] == 'Entertainment']
max_2 = samp2['avg_word_len'].mean()
samp3 = data2[data2['labels'] == 'Education']
max_3 = samp3['avg_word_len'].mean()
samp4 = data2[data2['labels'] == 'Environment']
max_4 = samp4['avg_word_len'].mean()
samp5 = data2[data2['labels'] == 'Sports']
max_5 = samp5['avg_word_len'].mean()
samp6 = data2[data2['labels'] == 'Technology']
max_6 = samp6['avg_word_len'].mean()
samp7 = data2[data2['labels'] == 'Health']
max_7 = samp7['avg_word_len'].mean()

plt.figure(figsize=(20,20))
plt.title('Average Word Length by Label', fontsize=48)
sns.kdeplot(data2[data2['labels']=='Economy']['avg_word_len'], shade=True, color='red', label='Economy')
sns.kdeplot(data2[data2['labels']=='Entertainment']['avg_word_len'], shade=True, color='magenta', label='Entertainment')
sns.kdeplot(data2[data2['labels']=='Education']['avg_word_len'], shade=True, color='blue', label='Education')
sns.kdeplot(data2[data2['labels']=='Environment']['avg_word_len'], shade=True, color='yellow', label ='Environment')
sns.kdeplot(data2[data2['labels']=='Sports']['avg_word_len'], shade=True, color= 'green', label='Sports')
sns.kdeplot(data2[data2['labels']=='Technology']['avg_word_len'], shade=True, color='purple',label='Technology')
sns.kdeplot(data2[data2['labels']=='Health']['avg_word_len'], shade=True, color='skyblue', label='Health')
plt.legend(fontsize='xx-large')
plt.xticks(fontsize=28)
plt.xlabel('Avg Word Length', fontsize=36)
# plt.xlim(left=0, right=8000)
plt.axvline(x=max_1, ymax=.25, color='red', linewidth=3)
plt.axvline(x=max_2, ymax=.25, color='magenta', linewidth=3)
plt.axvline(x=max_3, ymax=.25, color='blue', linewidth=3)
plt.axvline(x=max_4, ymax=.25, color='yellow', linewidth=3)
plt.axvline(x=max_5, ymax=.25, color='green', linewidth=3)
plt.axvline(x=max_6, ymax=.30, color='purple', linewidth=3)
plt.axvline(x=max_7, ymax=.25, color='skyblue', linewidth=3)
plt.yticks(fontsize=28)
plt.ylabel('Density', fontsize=36)
# plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/All_Label_Avg_Word_Length', transparent=True)
plt.show()

"""## Correlation Matrix Table """

data2.corr()

#Plotting the correlation matrix in the heatmap.
plt.figure(figsize=(15,7))
corr= data2.corr()
sns.heatmap(corr,annot= True,vmin=0,vmax=0.7, cmap='RdYlGn_r')

data2['labels'].unique()

data2.head()

data2.columns

data2

"""## Saving clean dataframe `"data2"`"""

data2.columns

data2.drop(columns=['stop_words_len', 'upper_case_counts', 'url_flags', 'emails', 'emails_count'], inplace=True)

data2.head()

data2.to_csv('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Datasets/clean_word_counts.csv',index=False)

"""## Creating Wordcloud"""

#!pip3 install wordcloud

import sys
print(sys.executable)

# Commented out IPython magic to ensure Python compatibility.
from wordcloud import WordCloud
import matplotlib.pyplot as plt
# %matplotlib inline

text = ' '.join(data2['clean'])

len(text)

plt.figure(figsize=(20,20))
# plt.title('WordCloud', fontsize=40)
wc = WordCloud(width=1600, height=800).generate(text)
plt.imshow(wc)
plt.axis('off')
plt.tight_layout(pad=0)
plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Full_WordCloud', transparent=True)
plt.show()