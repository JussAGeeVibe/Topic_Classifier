# -*- coding: utf-8 -*-
"""Project_6_Modeling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19KbIEdCB0eQNAantMzHNuqGtRGKvmruO
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import spacy
import numpy as np
import matplotlib.pyplot as plt
from sklearn import metrics
# %matplotlib inline

import seaborn as sns
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

#!pip install spacy

# importing libraries for NLP
import spacy
from spacy.lang.en.stop_words import STOP_WORDS as stopwords
import re

def make_confusion_matrix(model,x_actual,y_actual,labels=[1, 0], path=''):
    '''
    model : classifier to predict values of X
    y_actual : ground truth  
    
    '''
    y_predict = model.predict(x_actual)
    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[0, 1])
    df_cm = pd.DataFrame(cm, index = [i for i in ["Actual - No","Actual - Yes"]],
                  columns = [i for i in ['Predicted - No','Predicted - Yes']])
    group_counts = ["{0:0.0f}".format(value) for value in
                cm.flatten()]
    group_percentages = ["{0:.2%}".format(value) for value in
                         cm.flatten()/np.sum(cm)]
    # labels = [f"{v1}\n{v2}" for v1, v2 in
    #           zip(group_counts,group_percentages)]
    # labels = np.asarray(labels).reshape(2,2)
    plt.figure(figsize = (10,7))
    sns.heatmap(df_cm, fmt='')#,annot=labels)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.savefig(path, transparent=True)

"""# Importing Finished DataFrame for modeling"""

from google.colab import drive
drive.mount('/content/drive')

train_val = pd.read_parquet('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Datasets/train_val_df.parquet', engine='pyarrow')
# train_val.drop(columns=['Unnamed: 0'], inplace=True)
# test = pd.read_csv('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Datasets/test_df.csv')

train_val.info()

train_val.labels.value_counts()

train_val.columns

"""## Splitting Data and building Random_Forest Model with Pipeline"""

X_sum = train_val['sum_lem']
X_alp = train_val['comp_lem']
y_sum = train_val['labels']
y_alp = train_val['labels']

X_train_sum, X_test_sum, y_train_sum, y_test_sum = train_test_split(X_sum, y_sum, test_size=0.25, random_state=2)
X_train_alp, X_test_alp, y_train_alp, y_test_alp = train_test_split(X_alp, y_alp, test_size=0.25, random_state=2)

tfidvec = TfidfVectorizer(ngram_range=(1,2), max_features=50000)
tfid = tfidvec.fit_transform(X_alp)
tfid_ = tfid.toarray()
tfid_df = pd.DataFrame(tfid_, columns=tfidvec.get_feature_names())
print(tfid_df.shape)
tfid_df

"""## complete"""

text_clf_alp = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(n_jobs=-1, random_state=2))], verbose=True)

text_clf_alp.fit(X_train_alp, y_train_alp)

predictions = text_clf_alp.predict(X_test_alp)

print(confusion_matrix(y_test_alp,predictions))
print()
print(classification_report(y_test_alp, predictions))
print()
print(accuracy_score(y_test_alp, predictions))

"""## summary"""

text_clf_sum = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(n_jobs=-1, random_state=2))], verbose=True)

text_clf_sum.fit(X_train_sum, y_train_sum)

predictions = text_clf_sum.predict(X_test_sum)

print(confusion_matrix(y_test_sum,predictions))
print()
print(classification_report(y_test_sum, predictions))
print()
print(accuracy_score(y_test_sum, predictions))

"""## comp_stem

### Test cases
"""

text_clf_alp = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(max_depth= 8, n_estimators= 1250, n_jobs=-1, random_state=2))])

text_clf_alp.fit(X_train_alp, y_train_alp)

predictions = text_clf_alp.predict(X_test_alp)

print(confusion_matrix(y_test_alp,predictions))
print()
print(classification_report(y_test_alp, predictions))
print()
print(accuracy_score(y_test_alp, predictions))

"""### Best Case Params"""

#  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
#                                         class_weight=None, criterion='gini',
#                                         max_depth=10, max_features='auto',
#                                         max_leaf_nodes=None, max_samples=None,
#                                         min_impurity_decrease=0.0,
#                                         min_impurity_split=None,
#                                         min_samples_leaf=2, min_samples_split=3,
#                                         min_weight_fraction_leaf=0.0,
#                                         n_estimators=250, n_jobs=-1,
#                                         oob_score=False, random_state=2,
#                                         verbose=0, warm_start=False))]

predictions = best_grid.predict(X_test_alp)

print(confusion_matrix(y_test_alp,predictions))
print()
print(classification_report(y_test_alp, predictions))
print()
print(accuracy_score(y_test_alp, predictions))

"""### Base Case"""

text_clf_alp = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(n_jobs=-1, random_state=2))])

text_clf_alp.fit(X_train_alp, y_train_alp)

predictions = text_clf_alp.predict(X_test_alp)

print(confusion_matrix(y_test_alp,predictions))
print()
print(classification_report(y_test_alp, predictions))
print()
print(accuracy_score(y_test_alp, predictions))

predictions = text_clf_alp.predict(X_test_alp)
labs = ['Econ','Edu','Ent','Envir','Heal','Sports','Tech']
array = confusion_matrix(y_test_alp,predictions)
df_cm = pd.DataFrame(array, index = labs, columns = labs)
plt.figure(figsize=(20,20))
sns.heatmap(df_cm, annot=True, cmap='PiYG', annot_kws={"size": 30})
plt.title('Confusion Matrix Heatmap', fontsize=48)
plt.xticks(fontsize=30, rotation=30)
plt.yticks(fontsize=30, rotation=30)
plt.ylabel('Predicted', fontsize=22)
plt.xlabel('Actual', fontsize=22)
plt.savefig('/content/drive/MyDrive/EiT/Week_6/Presentation_6/Visualizations/Confusion_Matrix', transparent=True)
plt.show()

"""## sum_stem"""

text_clf_sum = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(n_jobs=-1, random_state=2))], verbose=True)

text_clf_sum.fit(X_train_sum, y_train_sum)

predictions = text_clf_sum.predict(X_test_sum)

print(confusion_matrix(y_test_sum,predictions))
print()
print(classification_report(y_test_sum, predictions))
print()
print(accuracy_score(y_test_sum, predictions))

"""## comp_lem"""

text_clf_alp = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(max_depth= 6, n_estimators= 5000, n_jobs=-1, random_state=2))], verbose=True)

text_clf_alp.fit(X_train_alp, y_train_alp)

predictions = text_clf_alp.predict(X_test_alp)
preds = text_clf_alp.predict(X_train_alp)

print(confusion_matrix(y_test_alp,predictions))
print()
# print(classification_report(y_test_alp, predictions))
print()
print('Train acc: ',accuracy_score(y_train_alp, preds)) 
print('Val acc: ',accuracy_score(y_test_alp, predictions))

text = 'Beyond individual developer preferences, we also have to accommodate the fact that station API users can see a lot of story content, photos and audio assets that public API users can\'t.'

text = '''Beyond individual developer preferences, we also have to 
          accommodate the fact that station API users can see a lot 
          of story content, photos and audio assets that public API users can\'t.'''

nlp = spacy.load('en_core_web_sm')
doc = nlp(str(text))
lemmed = ''
for sent in doc.sents:
  temp = ''
  for word in sent:
    temp += ' '+ word.lemma_
  lemmed += ' '+ temp
lemmed = [lemmed]

text_clf_alp.predict(lemmed)

"""## sum_lem"""

text_clf_sum = Pipeline([('tfidf', TfidfVectorizer()),
                     ('clf', RandomForestClassifier(max_depth= 7, n_estimators= 500,n_jobs=-1, random_state=2))], verbose=True)

text_clf_sum.fit(X_train_sum, y_train_sum)

predictions = text_clf_sum.predict(X_test_sum)
preds = text_clf_alp.predict(X_train_sum)

print(confusion_matrix(y_test_sum,predictions))
print()
print(classification_report(y_test_sum, predictions))
print()
print('Train acc: ',accuracy_score(y_train_sum, preds)) 
print('Val acc: ',accuracy_score(y_test_sum, predictions))

